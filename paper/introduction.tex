\section{Introduction}

The Grand Challenge 2015 problem focuses on processing New York city taxi trip data for year 2013. The area considered is a square of 150m x  150m. The  square is divided into smaller units called cells and a taxi trip is considered as moving from one cell (pickup cell) to another cell (dropoff cell). Therefore a route is uniquely identified by the pickup cell and the dropoff cell. The data set consists of 173 million events and solutions are expected to replay these data and generate events that meet criteria of two queries defined. 

The first query is to find the events which change the top ten routes within last 30 minutes and emit the new route set details along the original event. The given data set contains 899010  routes and the 30 minute time window for this query accounts around 10000 events assuming an equal event distribution. This creates the possibility of processing several thousand route counts specially within peak hours. In other words we need to evaluate several thousand route counts with each event and find 10 top most routes. Similar analysis can be made with profitable cells query as well. In addition to that it requires to  calculate the median fare for each cell. 

\subsection{Research Challengers}

If we consider an application to process this 173 million data set within an year, it would be a trivial task and any naive implementation satisfy that requirement. However if we consider an application which process these data within minutes with minimal latency to process each event, we observe following research challengers.
\begin{enumerate}
	\item \textit{Handling thousands of values in real time :}  An algorithm with O(n) time complexity will not scale for thousands. Therefore is it possible to come up with an algorithm of O(log(n)) time complexity?
	\item \textit{Parallel evaluation :}  This application is not inherently support parallel evaluation. Partitioning route sets and cell sets triggers events for sub sets, but application requires the events with whole sets. Therefore is it possible to partition data and still generate required results to support parallelism?  
\end{enumerate}

\subsection{Methodology}

We started our work seeking answers for above challengers. First we evaluated doubly linked list and heap based approaches to build a data structure with O(log(n)) time complexity. After several evaluations, we developed a new data structure called \textit{NodeList} which utilizes both concepts. In order to find the running median with O(log(n)) time complexity, we experimented with an algorithm which uses priority queue and the heap data structure we developed. We decided to use former since it gave better performance with smaller window sizes. Then we focused on parallelizing the application and came up with a strategy to aggregate the sub set results to find the final results. As the last step, we conducted several experiments to evaluate the scalability of our solution. We repeated this process identifying possible issues and fixing them.


\subsection{Contributions}
We observe following key contributions, which can be used in solving future DEBS challenges as well.
\begin{enumerate}
	\item We have developed a set of  generic data structures capable of inserting, updating, removing and retrieving top values (order can be defined using a comparator function) with O(log(n)) time complexity. 
	\item Using our data structures we have developed a new algorithm to find the running median with O(log(n)) time complexity. One of the key challenges of DEBS 2014 \cite{jerzak2014debs}  was to find the median of a large time window. We believe our solution is useful in such situations.
	\item We have developed a scalable parallel evaluation technique to process queries efficiently. 
\end{enumerate}

\subsection{Paper Organization}
The remainder of this paper is organized as follows. Section 2 provides an in-depth description about the internal data structures and the algorithms used to process the events. Section 3 describes our scalable design to evaluate queries and associated problems. Section 4 proves the scalability of our solution with experimental results. Section 5 discuss the related work including some last year solutions. Section 6 summarizes key concepts and discuss their further applications. 
